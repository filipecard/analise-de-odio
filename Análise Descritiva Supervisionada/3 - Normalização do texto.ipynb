{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização do texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Importação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./arquivos/clean.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>labels</th>\n",
       "      <th>length</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.6013</td>\n",
       "      <td>O</td>\n",
       "      <td>43</td>\n",
       "      <td>warning penny boards will make you a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>H</td>\n",
       "      <td>10</td>\n",
       "      <td>fuck dykes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>H</td>\n",
       "      <td>46</td>\n",
       "      <td>at least i dont look like jefree starr faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>H</td>\n",
       "      <td>28</td>\n",
       "      <td>is a fag jackie jealous nee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>O</td>\n",
       "      <td>88</td>\n",
       "      <td>you heard me bitch but any way i'm back th texas so wtf u talking about bitch ass nigga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>H</td>\n",
       "      <td>130</td>\n",
       "      <td>your a dirty terrorist and your religion is a fucking joke you go around screaming allah akbar doing terrorist shit dirty faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>H</td>\n",
       "      <td>24</td>\n",
       "      <td>rt looking like faggots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.5619</td>\n",
       "      <td>H</td>\n",
       "      <td>111</td>\n",
       "      <td>well i thought you knew actually rt man why y'all didn't tell me i was a dick riding ass faggot y'all not real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.6419</td>\n",
       "      <td>O</td>\n",
       "      <td>29</td>\n",
       "      <td>i know it was a joke faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.6407</td>\n",
       "      <td>O</td>\n",
       "      <td>104</td>\n",
       "      <td>i'm tired of people saying i look like my brother calling me deondre' like serious succ my ass fag asses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>H</td>\n",
       "      <td>125</td>\n",
       "      <td>voteblue2014 yeah cuz 8 million people in faggot ass newyork are chickenshit jews fuck them right fuck bibi netanyahu right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>H</td>\n",
       "      <td>53</td>\n",
       "      <td>word is you use roids stupid hypocrite lying faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>H</td>\n",
       "      <td>23</td>\n",
       "      <td>i hate faggots like you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>H</td>\n",
       "      <td>86</td>\n",
       "      <td>shut up nigger whore hope u get raped by one of those animals might change your tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>H</td>\n",
       "      <td>88</td>\n",
       "      <td>fuck you nigger sheboon hope you r strung up like all niggers should be whitepower 1488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    confidence labels  length  \\\n",
       "0       0.6013      O      43   \n",
       "1       0.7227      H      10   \n",
       "2       0.5229      H      46   \n",
       "3       0.5184      H      28   \n",
       "4       0.5185      O      88   \n",
       "5       0.8816      H     130   \n",
       "6       0.5207      H      24   \n",
       "7       0.5619      H     111   \n",
       "8       0.6419      O      29   \n",
       "9       0.6407      O     104   \n",
       "10      0.7619      H     125   \n",
       "11      0.5606      H      53   \n",
       "12      0.8435      H      23   \n",
       "13      0.8414      H      86   \n",
       "14      0.8826      H      88   \n",
       "\n",
       "                                                                                                                            tweet_text  \n",
       "0                                                                                          warning penny boards will make you a faggot  \n",
       "1                                                                                                                           fuck dykes  \n",
       "2                                                                                        at least i dont look like jefree starr faggot  \n",
       "3                                                                                                          is a fag jackie jealous nee  \n",
       "4                                              you heard me bitch but any way i'm back th texas so wtf u talking about bitch ass nigga  \n",
       "5    your a dirty terrorist and your religion is a fucking joke you go around screaming allah akbar doing terrorist shit dirty faggot   \n",
       "6                                                                                                             rt looking like faggots   \n",
       "7                      well i thought you knew actually rt man why y'all didn't tell me i was a dick riding ass faggot y'all not real   \n",
       "8                                                                                                         i know it was a joke faggot   \n",
       "9                             i'm tired of people saying i look like my brother calling me deondre' like serious succ my ass fag asses  \n",
       "10        voteblue2014 yeah cuz 8 million people in faggot ass newyork are chickenshit jews fuck them right fuck bibi netanyahu right   \n",
       "11                                                                                word is you use roids stupid hypocrite lying faggot   \n",
       "12                                                                                                             i hate faggots like you  \n",
       "13                                               shut up nigger whore hope u get raped by one of those animals might change your tune   \n",
       "14                                             fuck you nigger sheboon hope you r strung up like all niggers should be whitepower 1488  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(tweet for tweet in data.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['warning', 'penny', 'boards', 'will', 'make', 'you', 'a', 'faggot', 'fuck', 'dykes', 'at', 'least', 'i', 'dont', 'look', 'like', 'jefree', 'starr', 'faggot', 'is', 'a', 'fag', 'jackie', 'jealous', 'nee', 'you', 'heard', 'me', 'bitch', 'but', 'any', 'way', 'i', \"'m\", 'back', 'th', 'texas', 'so', 'wtf', 'u', 'talking', 'about', 'bitch', 'ass', 'nigga', 'your', 'a', 'dirty', 'terrorist', 'and', 'your', 'religion', 'is', 'a', 'fucking', 'joke', 'you', 'go', 'around', 'screaming', 'allah', 'akbar', 'doing', 'terrorist', 'shit', 'dirty', 'faggot', 'rt', 'looking', 'like', 'faggots', 'well', 'i', 'thought', 'you', 'knew', 'actually', 'rt', 'man', 'why', \"y'all\", 'did', \"n't\", 'tell', 'me', 'i', 'was', 'a', 'dick', 'riding', 'ass', 'faggot', \"y'all\", 'not', 'real', 'i', 'know', 'it', 'was', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tk = pd.DataFrame.from_dict(data.tweet_text.apply(nltk.word_tokenize))\n",
    "data_tk['words_count'] = pd.DataFrame.from_dict(data_tk.tweet_text.apply(len))\n",
    "data_tk['label'] = data.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contagem de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>words_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[warning, penny, boards, will, make, you, a, faggot]</td>\n",
       "      <td>8</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[fuck, dykes]</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[at, least, i, dont, look, like, jefree, starr, faggot]</td>\n",
       "      <td>9</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[is, a, fag, jackie, jealous, nee]</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[you, heard, me, bitch, but, any, way, i, 'm, back, th, texas, so, wtf, u, talking, about, bitch, ass, nigga]</td>\n",
       "      <td>20</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14504</td>\n",
       "      <td>[i, 'm, sorry, did, i, offend, your, white, supremacist, aryan, nation, neo, nazi, best, fascist, friends, somehow]</td>\n",
       "      <td>17</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14505</td>\n",
       "      <td>[caucasian, euro, aryan, whatever, really, does, n't, matter, they, 're, damn, sure, not, white]</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14506</td>\n",
       "      <td>[sir, a, patient, named, aryan, khan, village, meeranpur, pratapgarh, who, is, suffering, from, like, dengu, has, refferd, to, sgpgi, lko, help]</td>\n",
       "      <td>21</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14507</td>\n",
       "      <td>[happy, birthday, bro, ì, «, ìð, have, an, happy, year, ahead, ì, «, å, ì, «, ì, «, ê, ì, «, û, ì, «, û]</td>\n",
       "      <td>25</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14508</td>\n",
       "      <td>[aryan, kapoor, is, such, a, cute, name, tho, d, we, want, k, s, first, look]</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14509 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                                                                                                  [warning, penny, boards, will, make, you, a, faggot]   \n",
       "1                                                                                                                                         [fuck, dykes]   \n",
       "2                                                                                               [at, least, i, dont, look, like, jefree, starr, faggot]   \n",
       "3                                                                                                                    [is, a, fag, jackie, jealous, nee]   \n",
       "4                                         [you, heard, me, bitch, but, any, way, i, 'm, back, th, texas, so, wtf, u, talking, about, bitch, ass, nigga]   \n",
       "...                                                                                                                                                 ...   \n",
       "14504                               [i, 'm, sorry, did, i, offend, your, white, supremacist, aryan, nation, neo, nazi, best, fascist, friends, somehow]   \n",
       "14505                                                  [caucasian, euro, aryan, whatever, really, does, n't, matter, they, 're, damn, sure, not, white]   \n",
       "14506  [sir, a, patient, named, aryan, khan, village, meeranpur, pratapgarh, who, is, suffering, from, like, dengu, has, refferd, to, sgpgi, lko, help]   \n",
       "14507                                      [happy, birthday, bro, ì, «, ìð, have, an, happy, year, ahead, ì, «, å, ì, «, ì, «, ê, ì, «, û, ì, «, û]   \n",
       "14508                                                                     [aryan, kapoor, is, such, a, cute, name, tho, d, we, want, k, s, first, look]   \n",
       "\n",
       "       words_count label  \n",
       "0                8     O  \n",
       "1                2     H  \n",
       "2                9     H  \n",
       "3                6     H  \n",
       "4               20     O  \n",
       "...            ...   ...  \n",
       "14504           17     N  \n",
       "14505           14     N  \n",
       "14506           21     N  \n",
       "14507           25     N  \n",
       "14508           15     N  \n",
       "\n",
       "[14509 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras mais usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 5864, 'i': 5327, 'you': 5216, 'the': 5031, 'to': 4230, 'ì': 3543, 'is': 2575, '«': 2542, 'of': 2440, 'in': 2180, ...})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.DataFrame.from_dict(total_words, orient='index', columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "      <td>5864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>i</td>\n",
       "      <td>5327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>you</td>\n",
       "      <td>5216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>5031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>to</td>\n",
       "      <td>4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ì</td>\n",
       "      <td>3543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is</td>\n",
       "      <td>2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>«</td>\n",
       "      <td>2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>of</td>\n",
       "      <td>2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>in</td>\n",
       "      <td>2180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count\n",
       "a     5864\n",
       "i     5327\n",
       "you   5216\n",
       "the   5031\n",
       "to    4230\n",
       "ì     3543\n",
       "is    2575\n",
       "«     2542\n",
       "of    2440\n",
       "in    2180"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.sort_values(by=\"count\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porter Stemmer. (Geralmente mais rápido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stem = [stemmer.stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['warn', 'penni', 'board', 'will', 'make', 'you', 'faggot', 'fuck', 'dyke', 'least', 'dont', 'look', 'like', 'jefre', 'starr', 'faggot', 'fag', 'jacki', 'jealou', 'nee', 'you', 'heard', 'bitch', 'but', 'ani']\n"
     ]
    }
   ],
   "source": [
    "print(list(filter(lambda x : len(x) > 2, porter_stem))[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowball Stemmer. (Geralmente mais adequado para o inglês)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english', ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokenize(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    return [stemmer.lemmatize(token) for token in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['warn', 'penni', 'board', 'will', 'make', 'you', 'faggot', 'fuck', 'dyke', 'least', 'dont', 'look', 'like', 'jefre', 'starr', 'faggot', 'fag', 'jacki', 'jealous', 'nee', 'you', 'heard', 'bitch', 'but', 'any']\n"
     ]
    }
   ],
   "source": [
    "print(list(filter(lambda x : len(x) > 2, snowball_stem))[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_tokenize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lemm = [lemmatizer.lemmatize(w, pos='v') for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['warn', 'penny', 'board', 'will', 'make', 'you', 'faggot', 'fuck', 'dyke', 'least', 'dont', 'look', 'like', 'jefree', 'starr', 'faggot', 'fag', 'jackie', 'jealous', 'nee', 'you', 'hear', 'bitch', 'but', 'any']\n"
     ]
    }
   ],
   "source": [
    "print(list(filter(lambda x : len(x) > 2, word_lemm))[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Remover StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words_final = [word for word in word_lemm if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['warn', 'penny', 'board', 'make', 'faggot', 'fuck', 'dyke', 'least', 'dont', 'look', 'like', 'jefree', 'starr', 'faggot', 'fag', 'jackie', 'jealous', 'nee', 'hear', 'bitch', 'way', 'back', 'texas', 'wtf', 'talk']\n"
     ]
    }
   ],
   "source": [
    "print(list(filter(lambda x : len(x) > 2, words_final))[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15564"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = count_vectorizer.fit_transform(data.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = count_vectorizer.get_feature_names()\n",
    "bow = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0092</th>\n",
       "      <th>00mm</th>\n",
       "      <th>01622</th>\n",
       "      <th>023</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>041</th>\n",
       "      <th>042</th>\n",
       "      <th>...</th>\n",
       "      <th>ûóìöall</th>\n",
       "      <th>ûóìöd</th>\n",
       "      <th>ûóìöll</th>\n",
       "      <th>ûóìöm</th>\n",
       "      <th>ûóìöre</th>\n",
       "      <th>ûóìös</th>\n",
       "      <th>ûóìöt</th>\n",
       "      <th>ûóìöve</th>\n",
       "      <th>üå</th>\n",
       "      <th>üì</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14509 rows × 17322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  0092  00mm  01622  023  03  04  041  042  ...  ûóìöall  ûóìöd  \\\n",
       "0       0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "1       0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "2       0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "3       0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "4       0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "...    ..  ...   ...   ...    ...  ...  ..  ..  ...  ...  ...      ...    ...   \n",
       "14504   0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "14505   0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "14506   0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "14507   0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "14508   0    0     0     0      0    0   0   0    0    0  ...        0      0   \n",
       "\n",
       "       ûóìöll  ûóìöm  ûóìöre  ûóìös  ûóìöt  ûóìöve  üå  üì  \n",
       "0           0      0       0      0      0       0   0   0  \n",
       "1           0      0       0      0      0       0   0   0  \n",
       "2           0      0       0      0      0       0   0   0  \n",
       "3           0      0       0      0      0       0   0   0  \n",
       "4           0      0       0      0      0       0   0   0  \n",
       "...       ...    ...     ...    ...    ...     ...  ..  ..  \n",
       "14504       0      0       0      0      0       0   0   0  \n",
       "14505       0      0       0      0      0       0   0   0  \n",
       "14506       0      0       0      0      0       0   0   0  \n",
       "14507       0      0       0      0      0       0   0   0  \n",
       "14508       0      0       0      0      0       0   0   0  \n",
       "\n",
       "[14509 rows x 17322 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>labels</th>\n",
       "      <th>length</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>H</td>\n",
       "      <td>28</td>\n",
       "      <td>is a fag jackie jealous nee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.6407</td>\n",
       "      <td>O</td>\n",
       "      <td>104</td>\n",
       "      <td>i'm tired of people saying i look like my brother calling me deondre' like serious succ my ass fag asses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>H</td>\n",
       "      <td>111</td>\n",
       "      <td>good night fags and fagettes that's the female version of fags like fag ettes to make it female i hate you all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>947</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>H</td>\n",
       "      <td>100</td>\n",
       "      <td>you piece of shit i stepped on dog puke last night cause your faggot ass was feeding that fag fries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4145</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>O</td>\n",
       "      <td>53</td>\n",
       "      <td>going for a fag and ignoring her isnt the same thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14438</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>O</td>\n",
       "      <td>46</td>\n",
       "      <td>i wanna go on a walk with a fag and get lost p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14439</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>O</td>\n",
       "      <td>67</td>\n",
       "      <td>i still owe you a drink for you birthday fag let's go grab a drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14440</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>O</td>\n",
       "      <td>15</td>\n",
       "      <td>good video fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14441</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>N</td>\n",
       "      <td>57</td>\n",
       "      <td>just gave my mum a menthol fag and she can't hack it lool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14442</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>O</td>\n",
       "      <td>8</td>\n",
       "      <td>you fag</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       confidence labels  length  \\\n",
       "3          0.5184      H      28   \n",
       "9          0.6407      O     104   \n",
       "16         0.6833      H     111   \n",
       "947        1.0000      H     100   \n",
       "4145       1.0000      O      53   \n",
       "...           ...    ...     ...   \n",
       "14438      1.0000      O      46   \n",
       "14439      0.6821      O      67   \n",
       "14440      0.6599      O      15   \n",
       "14441      0.6718      N      57   \n",
       "14442      0.6700      O       8   \n",
       "\n",
       "                                                                                                            tweet_text  \n",
       "3                                                                                          is a fag jackie jealous nee  \n",
       "9             i'm tired of people saying i look like my brother calling me deondre' like serious succ my ass fag asses  \n",
       "16     good night fags and fagettes that's the female version of fags like fag ettes to make it female i hate you all   \n",
       "947                you piece of shit i stepped on dog puke last night cause your faggot ass was feeding that fag fries  \n",
       "4145                                                              going for a fag and ignoring her isnt the same thing  \n",
       "...                                                                                                                ...  \n",
       "14438                                                                   i wanna go on a walk with a fag and get lost p  \n",
       "14439                                               i still owe you a drink for you birthday fag let's go grab a drink  \n",
       "14440                                                                                                   good video fag  \n",
       "14441                                                        just gave my mum a menthol fag and she can't hack it lool  \n",
       "14442                                                                                                          you fag  \n",
       "\n",
       "[491 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[bow.fag >= 1]  #Localizar tweets com a palavra fag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - TF-IDF: Term frequency-inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-4813c97a0abb>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-4813c97a0abb>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    tfidf_vectorizer = TfidfVectorizer(tokenizer=)\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = tfidf_vectorizer.fit_transform(data.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "tfidf = pd.DataFrame(values.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf.loc[tfidf.fag >= 0.7]\n",
    "#bow.fag.loc[bow.fag >= 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict(\n",
    "    list(zip(data.labels,data.tweet_text, tfidf.fag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = ['label', 'tweet', 'fag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test.fag >= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[tfidf.lame >= 0.5].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usar lemmatizer tokenize como parametro da TfidfVectorizer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
